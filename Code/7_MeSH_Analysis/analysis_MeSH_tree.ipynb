{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle\n",
    "# import mowl\n",
    "# mowl.init_jvm(\"4g\")\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load depth graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "big_G = {}\n",
    "\n",
    "def read_json_file(filename):\n",
    "    with open(filename) as f:\n",
    "        js_graph = json.load(f)\n",
    "    return json_graph.node_link_graph(js_graph)\n",
    "\n",
    "big_G = read_json_file(\"../../Data/Output/MeSH_graph_with_depth.json\")\n",
    "\n",
    "print(big_G.nodes[\"D004628\"][\"Depth\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency analysis of MeSH terms in RELISH abstracts\n",
    "\n",
    "We will load a json file that contains all the MeSH terms that are mentioned in pubmed abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PMID                                     Title/Abstract  \\\n",
      "0  34694464  limit use dithionit quench determin topolog me...   \n",
      "1  34694463  isol post traumat astereognosi case base revie...   \n",
      "2  34694462  loss chromatin remodel ddm caus segreg distort...   \n",
      "3  34694461  identif novel genom wide pleiotrop associ oral...   \n",
      "4  34694460  rare frequent lethal complic pulmonari vein is...   \n",
      "\n",
      "                         MeshTerms             SemanticTypes  \n",
      "0                  D005456;D008565       T130;T192;T116;T123  \n",
      "1                  D006225;D013236                 T039;T023  \n",
      "2                  D017360;D029681                 T116;T002  \n",
      "3                          D058685                 T028;T045  \n",
      "4  D001281;D017115;D004937;D011667  T023;T047;T046;T190;T061  \n"
     ]
    }
   ],
   "source": [
    "df_TP = pd.DataFrame()\n",
    "MeSH_cnt = {}\n",
    "\n",
    "'''\n",
    "    Function to load the complete topic_categorization dataset.\n",
    "    https://drive.google.com/file/d/19C9rI3HFKqxD4eX8XhV87g0-ImITqm96/view?usp=sharing\n",
    "\n",
    "    Input:  path -> The path location of the topic_categorization dataset in tsv format.\n",
    "    Output: A DataFrame with the topic_categorization dataset \"PMID\", \"Title/Abstract\", \"MeshTerms\",\"SemanticTypes\"\n",
    "'''\n",
    "def load_Dataset(path):\n",
    "    global df_TP\n",
    "    df_TP = pd.read_csv(path,sep='\\t')\n",
    "    print(df_TP.head())\n",
    "\n",
    "load_Dataset(\"../../Data/Input/pubmed_abstracts+MeSH+STY_dataset.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_G_nodes = set([x[0] for x in list(big_G.nodes.items())])\n",
    "\n",
    "for k in big_G_nodes:\n",
    "    if(k not in MeSH_cnt):\n",
    "        MeSH_cnt[k] = 0\n",
    "\n",
    "'''\n",
    "    Function  count of the appearances of a MeSH terms in the pubmed_abstracts+MeSH+STY dataset.\n",
    "\n",
    "    Input:  \n",
    "    Output: A Dictionary with the  count of the appearances of a MeSH, when an MeSH appears its parents as well appear   \n",
    "            {MeSH id : CNT}\n",
    "'''\n",
    "def count_MeSH_in_Dataset():\n",
    "    for i in df_TP.index: \n",
    "        #print(df_semantic[\"Semantic Types\"][i])\n",
    "        split_types = df_TP[\"MeshTerms\"][i].split(\";\")\n",
    "        #print(split_types)\n",
    "        for MeSH in split_types:\n",
    "            if MeSH in big_G_nodes:\n",
    "                graph_id = MeSH\n",
    "                if(graph_id in MeSH_cnt):\n",
    "                    MeSH_cnt[graph_id] = MeSH_cnt[graph_id] + 1\n",
    "                else:\n",
    "                    MeSH_cnt[graph_id] = 1\n",
    "\n",
    "    #print(sorted(MeSH_cnt.items(), key=lambda kv:(-kv[1], -kv[0])))\n",
    "\n",
    "count_MeSH_in_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849\n"
     ]
    }
   ],
   "source": [
    "nx.set_node_attributes(big_G, MeSH_cnt, \"Frequency_Pubmed\")\n",
    "print(big_G.nodes[\"D000067565\"][\"Frequency_Pubmed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../Data/Output/RELISH_MeSH_graph_with_depth+freq.json\", \"w\") as fp:\n",
    "            json.dump(json_graph.node_link_data(big_G),fp,indent = 2) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'big_G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      2\u001b[0m Depth_vs_freq \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m node_id \u001b[39min\u001b[39;00m big_G\u001b[39m.\u001b[39mnodes:\n\u001b[1;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m(node_id \u001b[39min\u001b[39;00m big_G_nodes \u001b[39mand\u001b[39;00m MeSH_cnt[node_id] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m      5\u001b[0m         dpth \u001b[39m=\u001b[39m big_G\u001b[39m.\u001b[39mnodes[node_id][\u001b[39m\"\u001b[39m\u001b[39mDepth\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'big_G' is not defined"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "Depth_vs_freq = {}\n",
    "for node_id in big_G.nodes:\n",
    "    if(node_id in big_G_nodes and MeSH_cnt[node_id] != 0):\n",
    "        dpth = big_G.nodes[node_id][\"Depth\"]\n",
    "        freq = big_G.nodes[node_id][\"Frequency_Pubmed\"]\n",
    "        if(dpth in Depth_vs_freq): Depth_vs_freq[dpth] += freq\n",
    "        else: Depth_vs_freq[dpth] = freq        \n",
    "        i+=1\n",
    "    # if(i == 20): break\n",
    "\n",
    "sortedKeys = list(Depth_vs_freq.keys())\n",
    "sortedKeys.sort()\n",
    "Depth_vs_freq = {i: Depth_vs_freq[i] for i in sortedKeys}\n",
    "\n",
    "df_Depth_vs_freq = pd.DataFrame()\n",
    "df_Depth_vs_freq['Depth in Mesh Tree'] = list(Depth_vs_freq.keys())\n",
    "df_Depth_vs_freq['MeSH count'] = list(Depth_vs_freq.values())\n",
    "\n",
    "print(df_Depth_vs_freq)\n",
    "sns.barplot(df_Depth_vs_freq, x=\"Depth in Mesh Tree\", y=\"MeSH count\").set(title='MeSH depth frequencies in RELISH abstracts')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph2doc2vec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1bed0e639ae37f4873fb0f11e8a4526b2621243edb4f8734a70cd3367cf8a468"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
